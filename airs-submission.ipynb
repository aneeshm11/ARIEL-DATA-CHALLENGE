{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70367,"databundleVersionId":9188054,"sourceType":"competition"},{"sourceId":9629432,"sourceType":"datasetVersion","datasetId":5846888},{"sourceId":9770233,"sourceType":"datasetVersion","datasetId":5618537}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --no-index --find-links=/kaggle/input/ariel-2024-pqdm pqdm\n# !pip install astropy","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-10-31T08:30:48.732666Z","iopub.execute_input":"2024-10-31T08:30:48.733448Z","iopub.status.idle":"2024-10-31T08:31:17.737684Z","shell.execute_reply.started":"2024-10-31T08:30:48.733396Z","shell.execute_reply":"2024-10-31T08:31:17.734955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom astropy.stats import sigma_clip\nimport os \nimport pandas as pd\nimport pandas.api.types\nimport scipy.stats\nfrom tqdm import tqdm\nimport itertools\nfrom scipy.optimize import minimize\nfrom sklearn.metrics import mean_squared_error\nimport plotly.express as px\nimport matplotlib.pyplot as plt \nfrom scipy.stats import skew\nfrom scipy.stats import kurtosis\nfrom scipy.stats import entropy\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-10-31T08:31:17.741537Z","iopub.execute_input":"2024-10-31T08:31:17.742103Z","iopub.status.idle":"2024-10-31T08:31:17.759006Z","shell.execute_reply.started":"2024-10-31T08:31:17.742039Z","shell.execute_reply":"2024-10-31T08:31:17.757233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.signal import savgol_filter\n\ndef smooth_data(data, window_size):\n    return savgol_filter(data, window_size, 3)\n\ndef optimize_breakpoint(data, initial_breakpoint, window_size, buffer_size, smooth_window):\n    best_breakpoint = initial_breakpoint\n    best_score = float(\"-inf\")\n    midpoint = len(data) // 2\n    smoothed_data = smooth_data(data, smooth_window)\n#     smoothed_data=data\n    for i in range(-window_size, window_size):\n        new_breakpoint = initial_breakpoint + i\n        if new_breakpoint > buffer_size and new_breakpoint < midpoint - buffer_size:\n            region1 = data[: new_breakpoint - buffer_size]\n            region2 = data[\n                new_breakpoint\n                + buffer_size : 2 * midpoint\n                - new_breakpoint\n                - buffer_size\n            ]\n            region3 = data[2 * midpoint - new_breakpoint + buffer_size :]\n\n            breakpoint_region1 = smoothed_data[new_breakpoint - buffer_size: new_breakpoint + buffer_size]\n            breakpoint_region2 = smoothed_data[new_breakpoint - buffer_size: new_breakpoint + buffer_size]\n\n            mean_diff = abs(np.mean(region1) - np.mean(region2)) + abs(\n                np.mean(region2) - np.mean(region3)\n            )\n            var_sum = np.var(region1) + np.var(region2) + np.var(region3)\n            range_at_breakpoint1 = (np.max(breakpoint_region1) - np.min(breakpoint_region1))\n            range_at_breakpoint2 = (np.max(breakpoint_region2) - np.min(breakpoint_region2))\n\n            mean_range_at_breakpoint = (range_at_breakpoint1 + range_at_breakpoint2) / 2\n\n            score = mean_diff - 0.5 * var_sum + mean_range_at_breakpoint\n\n            if score > best_score:\n                best_score = score\n                best_breakpoint = new_breakpoint\n\n                \n    return best_breakpoint","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:31:17.763351Z","iopub.execute_input":"2024-10-31T08:31:17.763787Z","iopub.status.idle":"2024-10-31T08:31:17.783417Z","shell.execute_reply.started":"2024-10-31T08:31:17.763744Z","shell.execute_reply":"2024-10-31T08:31:17.780487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_spectra(signal, phase1, phase2, power):\n    def objective_to_minimize(s, power, delta=2):\n        x = list(range(len(signal) - delta * 4))\n        \n        y = (\n            signal[: phase1 - delta].tolist()\n            + (signal[phase1 + delta : phase2 - delta] * (1 + s)).tolist()\n            + signal[phase2 + delta :].tolist()\n        )\n        \n        z = np.polyfit(x, y, deg=power)\n        p = np.poly1d(z)\n        error = np.abs(p(x) - y).mean()\n        \n        return error\n    \n    if len(signal.shape) > 1:\n        signal = signal.mean(axis=1)\n    \n    result = minimize(\n        fun=lambda s: objective_to_minimize(s[0], power),\n        x0=[0.0001],\n        method=\"Nelder-Mead\",\n        options={\"maxiter\": 500}\n    )\n            \n    return result.x[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:31:17.787832Z","iopub.execute_input":"2024-10-31T08:31:17.788769Z","iopub.status.idle":"2024-10-31T08:31:17.802836Z","shell.execute_reply.started":"2024-10-31T08:31:17.788698Z","shell.execute_reply":"2024-10-31T08:31:17.801506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_linear_corr(signal, linear_corr):\n    \"\"\"Apply linear correction to the signal\"\"\"\n    linear_corr = np.flip(linear_corr, axis=0)\n    corrected_signal = signal.copy()\n    \n    for x, y in np.ndindex(signal.shape[1:]):\n        poli = np.poly1d(linear_corr[:, x, y])\n        corrected_signal[:, x, y] = poli(signal[:, x, y])\n    return corrected_signal\n\ndef clean_dark(signal, dark):\n    \"\"\"Clean dark frame from signal\"\"\"\n    # Correct timing pattern for AIRS\n    dt = np.ones(len(signal)) * 0.1\n    dt[1::2] += 4.5  # Alternate frames have different exposure time\n    dark = np.tile(dark, (signal.shape[0], 1, 1))\n    return signal - dark * dt[:, np.newaxis, np.newaxis]\n\ndef process_signal(signal, gain, offset, dead, flat, dark, linear_corr):\n    \"\"\"Process AIRS signal with all calibration steps\"\"\"\n    cut_inf, cut_sup = 39, 321\n    \n    # Reshape signal to correct dimensions if needed\n    if signal.ndim != 3:\n        signal = signal.reshape(11250, 32, 356)\n    \n    # Convert to physical units\n    signal = signal / gain + offset\n    signal = signal.clip(0)  # Remove negative values\n    \n    # Apply wavelength cuts\n    signal = signal[:, :, cut_inf:cut_sup]\n    linear_corr = linear_corr[:, :, cut_inf:cut_sup]\n    dark = dark[:, cut_inf:cut_sup]\n    dead = dead[:, cut_inf:cut_sup]\n    flat = flat[:, cut_inf:cut_sup]\n    \n    # Apply linear correction\n    signal = apply_linear_corr(signal, linear_corr)\n    \n    # Clean dark frame\n    signal = clean_dark(signal, dark)\n    \n    # Handle dead pixels and hot pixels\n    hot = sigma_clip(dark, sigma=5, maxiters=5).mask\n    flat = flat.reshape(1, 32, flat.shape[-1])\n    flat[dead.reshape(1, 32, -1)] = np.nan\n    flat[hot.reshape(1, 32, -1)] = np.nan\n    \n    # Apply flat field correction\n    signal = signal / flat\n    \n    # Take center pixels (10:22)\n    signal = signal[:, 10:22, :]\n    \n    return signal\n\ndef apply_cds(signal):\n    \"\"\"Apply Correlated Double Sampling (odd-even subtraction)\"\"\"\n    # Average over spatial dimension first\n    mean_signal = np.nanmean(signal, axis=1)\n    # Subtract even from odd frames\n    cds_signal = mean_signal[1::2] - mean_signal[0::2]\n    return cds_signal\n\ndef bin_signal(signal, binning=30):\n    \"\"\"Bin the signal in time dimension\"\"\"\n    n_points = signal.shape[0] \n    n_bins = n_points // binning\n    \n    binned = np.zeros((n_bins, signal.shape[1]))\n    for j in range(n_bins):\n        start_idx = j * binning\n        end_idx = start_idx + binning\n        binned[j] = np.nanmean(signal[start_idx:end_idx], axis=0)\n    \n    return binned","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:31:17.804674Z","iopub.execute_input":"2024-10-31T08:31:17.805152Z","iopub.status.idle":"2024-10-31T08:31:17.829543Z","shell.execute_reply.started":"2024-10-31T08:31:17.805108Z","shell.execute_reply":"2024-10-31T08:31:17.827428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mode=\"test\"\nfiles= sorted(os.listdir(f\"/kaggle/input/ariel-data-challenge-2024/{mode}\"))\nplanets=[]\n\nfor f in files:\n    planets.append(int(f))\nplanets.sort()\nplanets=planets[:]\nprint(len(planets))\nprint(planets[0])","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:31:17.832010Z","iopub.execute_input":"2024-10-31T08:31:17.832609Z","iopub.status.idle":"2024-10-31T08:31:17.853673Z","shell.execute_reply.started":"2024-10-31T08:31:17.832547Z","shell.execute_reply":"2024-10-31T08:31:17.852285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nadc_info = pd.read_csv(f'/kaggle/input/ariel-data-challenge-2024/{mode}_adc_info.csv')\nplanet_scales=[]\n\n\ninitial_breakpoint=60\nbuffer_size=5\nsmooth_window=10\nwindow_size=5\n\nfor planet in planets:\n    print(f\"\\nProcessing planet: {planet}\")\n    planet = int(planet) \n    \n    # Load calibration data\n    airs_dark = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/AIRS-CH0_calibration/dark.parquet').values.reshape(32, 356)\n    airs_dead = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/AIRS-CH0_calibration/dead.parquet').values.reshape(32, 356)    \n    airs_flat = pd.read_parquet( f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/AIRS-CH0_calibration/flat.parquet').values.reshape(32, 356)\n    airs_linear_corr = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/AIRS-CH0_calibration/linear_corr.parquet').values.reshape(6, 32, 356)\n    \n    # Load signal data\n    airs_ch0 = pd.read_parquet( f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/AIRS-CH0_signal.parquet').values.reshape(11250, 32, 356)\n    \n    selected_adc_info = adc_info.loc[adc_info['planet_id'] == planet]\n    airs_ch0_gain = selected_adc_info['AIRS-CH0_adc_gain'].values[0]\n    airs_ch0_offset = selected_adc_info['AIRS-CH0_adc_offset'].values[0]\n    \n    processed = process_signal(airs_ch0, airs_ch0_gain, airs_ch0_offset,  airs_dead, airs_flat, airs_dark, airs_linear_corr)\n    \n    cds_signal = apply_cds(processed)\n    binned_signal = bin_signal(cds_signal, binning=30)\n            \n    af= binned_signal\n    af = np.array(af[ : , :])\n    af = np.nanmean(af , axis=(1 ))\n\n    \n    airsbp = optimize_breakpoint(af,initial_breakpoint,window_size=window_size,buffer_size=buffer_size,smooth_window=smooth_window)\n    midpoint1 = len(af) // 2\n    bp1 = [airsbp, 2 * midpoint1 - airsbp]\n    ingress_start   =  bp1[0] - buffer_size\n    ingress_end     =  bp1[0] + buffer_size\n    egress_start =  bp1[1] - buffer_size\n    egress_end   =  bp1[1] + buffer_size\n    \n    breakpoints = [ingress_start, ingress_end, egress_start, egress_end ]\n\n    signal_data=af \n    \n    a,b,c,d = breakpoints \n    p_scale=predict_spectra(signal_data, (a+b)//2 , (c+d)//2   , power=3  )\n    \n    planet_scales.append(p_scale)\n        \n    \n    count += 1\n    print(f\"saved planet number {planet}\", f\"total {count}\", binned_signal.shape)\nprint(\"done\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:31:17.855570Z","iopub.execute_input":"2024-10-31T08:31:17.856044Z","iopub.status.idle":"2024-10-31T08:31:24.038757Z","shell.execute_reply.started":"2024-10-31T08:31:17.856000Z","shell.execute_reply":"2024-10-31T08:31:24.037545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(planet_scales)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:31:24.040616Z","iopub.execute_input":"2024-10-31T08:31:24.041024Z","iopub.status.idle":"2024-10-31T08:31:24.046409Z","shell.execute_reply.started":"2024-10-31T08:31:24.040980Z","shell.execute_reply":"2024-10-31T08:31:24.045079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wave_scales = np.load(\"/kaggle/input/arieldata/wavescales_power3_spline.npy\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:32:35.957473Z","iopub.execute_input":"2024-10-31T08:32:35.958058Z","iopub.status.idle":"2024-10-31T08:32:35.969820Z","shell.execute_reply.started":"2024-10-31T08:32:35.957999Z","shell.execute_reply":"2024-10-31T08:32:35.968201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final=[]\n\nfor ps in planet_scales:\n    \n    wavelengths=[]\n    for ws in wave_scales:\n        wavelengths.append(ps * ws)\n        \n    wavelengths=np.abs(np.array(wavelengths))\n    final.append(wavelengths)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:32:36.864699Z","iopub.execute_input":"2024-10-31T08:32:36.865286Z","iopub.status.idle":"2024-10-31T08:32:36.873808Z","shell.execute_reply.started":"2024-10-31T08:32:36.865230Z","shell.execute_reply":"2024-10-31T08:32:36.872108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(final[0][:5])","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:32:38.165377Z","iopub.execute_input":"2024-10-31T08:32:38.165974Z","iopub.status.idle":"2024-10-31T08:32:38.174516Z","shell.execute_reply.started":"2024-10-31T08:32:38.165920Z","shell.execute_reply":"2024-10-31T08:32:38.172730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.array(final)\ncolumns = ['planet_id'] + [f'wl_{i+1}' for i in range(283)] + [f'sigma_{i+1}' for i in range(283)]\nsubmit_df = pd.DataFrame(columns=columns)\n\nvals=planets\n\nuncertainity = 6e-4\nprint(uncertainity)\nrows_list = []  \n\nfor i in range(len(vals)):  \n    row_data = {\n        'planet_id': vals[i]\n    }\n    \n    for j in range(283):\n        row_data[f'wl_{j+1}'] = predictions[i, j]\n    \n    for j in range(283):\n        row_data[f'sigma_{j+1}'] = uncertainity\n    \n    rows_list.append(row_data)\n\nsubmit_df = pd.DataFrame(rows_list)\n\nsubmit_df.to_csv(\"submission.csv\", index=False)\nprint(\"saved\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T08:15:26.011553Z","iopub.status.idle":"2024-10-31T08:15:26.012287Z","shell.execute_reply.started":"2024-10-31T08:15:26.011913Z","shell.execute_reply":"2024-10-31T08:15:26.011948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}