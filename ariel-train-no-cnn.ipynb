{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-22T11:24:47.849956Z","iopub.status.busy":"2024-10-22T11:24:47.849304Z","iopub.status.idle":"2024-10-22T11:24:52.546053Z","shell.execute_reply":"2024-10-22T11:24:52.544939Z","shell.execute_reply.started":"2024-10-22T11:24:47.849918Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os \n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from scipy.stats import skew\n","from scipy.stats import kurtosis\n","from scipy.stats import entropy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T11:24:52.548835Z","iopub.status.busy":"2024-10-22T11:24:52.548335Z","iopub.status.idle":"2024-10-22T11:24:52.559453Z","shell.execute_reply":"2024-10-22T11:24:52.558332Z","shell.execute_reply.started":"2024-10-22T11:24:52.548797Z"},"trusted":true},"outputs":[],"source":["def vector(data, start, end , start1 , end1):\n","    \n","    region1= data[:start]  \n","    \n","    region2=data[start:end]\n","    region3=data[end:start1]\n","    region4=data[start1:end1]\n","\n","    region5=data[end1:]\n","\n","    uncovered = (  np.mean(region1) + np.mean(region5)  )/2\n","    \n","    reduction1= ( uncovered - np.mean(region2)    ) / uncovered\n","    reduction2= ( uncovered - np.mean(region3)   )  / uncovered\n","    reduction3= ( uncovered - np.mean(region4)   )  / uncovered\n","        \n","    \n","    slope=(data[end]-data[start])/(end-start)\n","    slope1=(data[end1]-data[start1])/(end1-start1)\n","    \n","    nr = np.mean(data)    / np.std(data)\n","    nr1= np.mean(region1) / np.std(region1)\n","    nr2= np.mean(region2) / np.std(region2)\n","    nr3= np.mean(region3) / np.std(region3)\n","    nr4= np.mean(region4) / np.std(region4)\n","    nr5= np.mean(region5) / np.std(region5)\n","   \n","    skewness= skew(data)\n","\n","    input_vector = np.array([ slope, slope1 , reduction1, reduction2, reduction3 ,nr,nr1,nr2,nr3,nr4,nr5 ,skewness] )\n","\n","    return input_vector\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T11:24:52.561891Z","iopub.status.busy":"2024-10-22T11:24:52.561506Z","iopub.status.idle":"2024-10-22T11:24:52.623523Z","shell.execute_reply":"2024-10-22T11:24:52.622585Z","shell.execute_reply.started":"2024-10-22T11:24:52.561856Z"},"trusted":true},"outputs":[],"source":["from scipy.signal import savgol_filter\n","\n","def smooth_data(data, window_size):\n","    return savgol_filter(data, window_size, 3)\n","\n","def optimize_breakpoint(data, initial_breakpoint, window_size, buffer_size, smooth_window):\n","    best_breakpoint = initial_breakpoint\n","    best_score = float(\"-inf\")\n","    midpoint = len(data) // 2\n","    smoothed_data = smooth_data(data, smooth_window)\n","#     smoothed_data=data\n","    for i in range(-window_size, window_size):\n","        new_breakpoint = initial_breakpoint + i\n","        if new_breakpoint > buffer_size and new_breakpoint < midpoint - buffer_size:\n","            region1 = data[: new_breakpoint - buffer_size]\n","            region2 = data[\n","                new_breakpoint\n","                + buffer_size : 2 * midpoint\n","                - new_breakpoint\n","                - buffer_size\n","            ]\n","            region3 = data[2 * midpoint - new_breakpoint + buffer_size :]\n","\n","            breakpoint_region1 = smoothed_data[new_breakpoint - buffer_size: new_breakpoint + buffer_size]\n","            breakpoint_region2 = smoothed_data[new_breakpoint - buffer_size: new_breakpoint + buffer_size]\n","\n","            mean_diff = abs(np.mean(region1) - np.mean(region2)) + abs(\n","                np.mean(region2) - np.mean(region3)\n","            )\n","            var_sum = np.var(region1) + np.var(region2) + np.var(region3)\n","            range_at_breakpoint1 = (np.max(breakpoint_region1) - np.min(breakpoint_region1))\n","            range_at_breakpoint2 = (np.max(breakpoint_region2) - np.min(breakpoint_region2))\n","\n","            mean_range_at_breakpoint = (range_at_breakpoint1 + range_at_breakpoint2) / 2\n","\n","            score = mean_diff - 0.5 * var_sum + mean_range_at_breakpoint\n","\n","            if score > best_score:\n","                best_score = score\n","                best_breakpoint = new_breakpoint\n","\n","                \n","    return best_breakpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T11:24:52.625441Z","iopub.status.busy":"2024-10-22T11:24:52.624975Z","iopub.status.idle":"2024-10-22T11:24:52.632941Z","shell.execute_reply":"2024-10-22T11:24:52.631742Z","shell.execute_reply.started":"2024-10-22T11:24:52.625406Z"},"trusted":true},"outputs":[],"source":["# import torch\n","# import torch.nn as nn\n","\n","# class WavelengthPredictor(nn.Module):\n","#     def __init__(self):\n","#         super(WavelengthPredictor, self).__init__()\n","#         self.model = nn.Sequential(\n","#             # Initial expansion from 24 to wider dimensions\n","#             nn.Linear(24, 64),\n","#             nn.BatchNorm1d(64),\n","#             nn.ReLU(),\n","#             nn.Linear(64, 128),\n","            \n","#             # First dense block\n","#             nn.Linear(128, 256),\n","#             nn.BatchNorm1d(256),\n","#             nn.ReLU(),\n","#             nn.Linear(256, 512),\n","#             nn.BatchNorm1d(512),\n","#             nn.ReLU(),\n","            \n","#             # Second dense block with residual-like double linear\n","#             nn.Linear(512, 512),\n","#             nn.Linear(512, 512),\n","#             nn.BatchNorm1d(512),\n","#             nn.ReLU(),\n","            \n","#             # Third dense block\n","#             nn.Linear(512, 768),\n","#             nn.BatchNorm1d(768),\n","#             nn.ReLU(),\n","#             nn.Linear(768, 512),\n","#             nn.BatchNorm1d(512),\n","#             nn.ReLU(),\n","            \n","#             # Fourth dense block\n","#             nn.Linear(512, 384),\n","#             nn.BatchNorm1d(384),\n","#             nn.ReLU(),\n","#             nn.Linear(384, 384),\n","#             nn.BatchNorm1d(384),\n","#             nn.ReLU(),\n","            \n","#             # Final contraction to target dimension\n","#             nn.Linear(384, 283)\n","#         )\n","        \n","#         # Initialize weights for better gradient flow\n","#         self._initialize_weights()\n","    \n","#     def _initialize_weights(self):\n","#         for m in self.modules():\n","#             if isinstance(m, nn.Linear):\n","#                 nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","#                 if m.bias is not None:\n","#                     nn.init.constant_(m.bias, 0)\n","#             elif isinstance(m, nn.BatchNorm1d):\n","#                 nn.init.constant_(m.weight, 1)\n","#                 nn.init.constant_(m.bias, 0)\n","    \n","#     def forward(self, x):\n","#         return self.model(x)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T11:24:52.636974Z","iopub.status.busy":"2024-10-22T11:24:52.636355Z","iopub.status.idle":"2024-10-22T11:24:52.649826Z","shell.execute_reply":"2024-10-22T11:24:52.648738Z","shell.execute_reply.started":"2024-10-22T11:24:52.636937Z"},"trusted":true},"outputs":[],"source":["class WavelengthPredictor(nn.Module):\n","    def __init__(self, dropout_rate=0.2):\n","        super(WavelengthPredictor, self).__init__()\n","        self.model = nn.Sequential(\n","            # Initial layer with gradual size increase\n","            nn.Linear(24, 48),\n","            nn.BatchNorm1d(48),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","            \n","            # Hidden layer 1\n","            nn.Linear(48, 96),\n","            nn.BatchNorm1d(96),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","            \n","            # Hidden layer 2\n","            nn.Linear(96, 192),\n","            nn.BatchNorm1d(192),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","            \n","            # Hidden layer 3\n","            nn.Linear(192, 256),\n","            nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","            \n","            # Final layer with more gradual reduction\n","            nn.Linear(256, 283)\n","        )\n","        \n","        self._initialize_weights()\n","    \n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                # Using Xavier/Glorot initialization for better gradient flow\n","                nn.init.xavier_normal_(m.weight)\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.BatchNorm1d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","    \n","    def forward(self, x):\n","        return self.model(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T11:24:52.651851Z","iopub.status.busy":"2024-10-22T11:24:52.651466Z","iopub.status.idle":"2024-10-22T11:24:52.667242Z","shell.execute_reply":"2024-10-22T11:24:52.666290Z","shell.execute_reply.started":"2024-10-22T11:24:52.651808Z"},"trusted":true},"outputs":[],"source":["def planetnumber(filename):\n","    return int(filename.split('_')[0])\n","\n","class ARIEL(Dataset):\n","    def __init__(self, airs_dir, fgs_dir , start , end ):\n","        self.airs_dir = airs_dir\n","        self.fgs_dir = fgs_dir\n","        \n","        self.airs_list = sorted(os.listdir(self.airs_dir), key=planetnumber)[start:end]\n","        self.fgs_list = sorted(os.listdir(self.fgs_dir), key=planetnumber)[start:end]\n","    \n","    def __getitem__(self, index):\n","        \n","        airs_file = os.path.join(self.airs_dir, self.airs_list[index])\n","        fgs_file = os.path.join(self.fgs_dir, self.fgs_list[index])\n","        \n","        planet =  planetnumber(self.airs_list[index])\n","        \n","        airs_arr = np.load(airs_file)\n","        fgs_arr  = np.load(fgs_file) \n","        \n","        airs_arr=(airs_arr-np.min(airs_arr))/(np.max(airs_arr)-np.min(airs_arr))\n","        fgs_arr=(fgs_arr-np.min(fgs_arr))/(np.max(fgs_arr)-np.min(fgs_arr))\n","        \n","        initial_breakpoint=900\n","        buffer_size=80 \n","        smooth_window=200\n","        window_size=300\n","\n","        airsbp = optimize_breakpoint(airs_arr,initial_breakpoint,window_size=window_size,buffer_size=buffer_size,smooth_window=smooth_window)\n","        fgsbp = optimize_breakpoint(fgs_arr,initial_breakpoint,window_size=window_size,buffer_size=buffer_size,smooth_window=250)\n","\n","        midpoint1 = len(airs_arr) // 2\n","        bp1 = [airsbp, 2 * midpoint1 - airsbp]\n","        airs_start   =  bp1[0] - buffer_size\n","        airs_end     =  bp1[0] + buffer_size\n","        airs_start1  =  bp1[1] - buffer_size\n","        airs_end1    =  bp1[1] + buffer_size\n","        \n","        midpoint2 = len(fgs_arr) // 2\n","        bp2 = [fgsbp, 2 * midpoint2 - fgsbp]\n","        fgs_start  =    bp2[0] - buffer_size\n","        fgs_end    =    bp2[0] + buffer_size\n","        fgs_start1 =    bp2[1] - buffer_size\n","        fgs_end1   =    bp2[1] + buffer_size\n","\n","\n","        airs_vector=  vector( airs_arr,  airs_start ,  airs_end , airs_start1 , airs_end1 )\n","        fgs_vector =  vector( fgs_arr, fgs_start  ,   fgs_end , fgs_start1  , fgs_end1 )        \n","        \n","        \n","        input_vector=  np.concatenate((airs_vector , fgs_vector))\n","\n","        \n","        labels        = pd.read_csv(\"/kaggle/input/ariel-data-challenge-2024/train_labels.csv\")\n","        filtered_data = labels[labels[\"planet_id\"] == planet].iloc[0, 1:].values\n","        \n","        \n","        input_vector = torch.tensor(np.array(input_vector))\n","\n","        output       = torch.tensor(filtered_data )\n","\n","        \n","        return input_vector , output  , planet\n","     \n","    def __len__(self):\n","        return len(self.airs_list)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T11:24:52.668921Z","iopub.status.busy":"2024-10-22T11:24:52.668556Z","iopub.status.idle":"2024-10-22T11:24:54.103608Z","shell.execute_reply":"2024-10-22T11:24:54.102847Z","shell.execute_reply.started":"2024-10-22T11:24:52.668879Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","model = WavelengthPredictor()\n","model = nn.DataParallel(model)\n","model = model.to(device)\n","\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-2 , weight_decay=1e-4 )\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,  factor=0.5, patience=3 , min_lr=1e-8)\n","\n","# weights=\"/kaggle/input/arieldata/epoch140.pth\"\n","weights=None\n","\n","if weights:\n","    checkpoint = torch.load(weights, map_location=device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","    start_epoch = checkpoint['epoch'] + 1\n","    print(f\"Resuming from epoch {start_epoch}\")\n","    print(f\"Resuming learning rate: {optimizer.param_groups[0]['lr']}\")\n","\n","    \n","else:\n","    start_epoch = 0\n","    \n","batchsize1=24\n","batchsize2=2\n","\n","train_data = ARIEL(\"/kaggle/input/arieldata/airs2k\", \"/kaggle/input/arieldata/fgs2k\" , start=0 , end=612)\n","train_dataloader = DataLoader(train_data, batch_size=batchsize1, shuffle=True)\n","\n","val_data = ARIEL(\"/kaggle/input/arieldata/airs2k\", \"/kaggle/input/arieldata/fgs2k\" , start=612 , end=662)\n","val_dataloader = DataLoader(val_data, batch_size=batchsize2, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T11:24:54.105702Z","iopub.status.busy":"2024-10-22T11:24:54.104859Z","iopub.status.idle":"2024-10-22T11:24:54.110367Z","shell.execute_reply":"2024-10-22T11:24:54.109492Z","shell.execute_reply.started":"2024-10-22T11:24:54.105654Z"},"trusted":true},"outputs":[],"source":["print(len(train_dataloader))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T11:24:54.112183Z","iopub.status.busy":"2024-10-22T11:24:54.111599Z","iopub.status.idle":"2024-10-22T11:24:54.119492Z","shell.execute_reply":"2024-10-22T11:24:54.118575Z","shell.execute_reply.started":"2024-10-22T11:24:54.112137Z"},"trusted":true},"outputs":[],"source":["print(\"only airs , features = 24\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T11:24:54.121218Z","iopub.status.busy":"2024-10-22T11:24:54.120588Z","iopub.status.idle":"2024-10-22T11:24:54.129937Z","shell.execute_reply":"2024-10-22T11:24:54.129094Z","shell.execute_reply.started":"2024-10-22T11:24:54.121165Z"},"trusted":true},"outputs":[],"source":["num_params = sum(p.numel() for p in model.parameters())\n","print(f\"Number of parameters: {num_params}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T11:24:54.131546Z","iopub.status.busy":"2024-10-22T11:24:54.131154Z","iopub.status.idle":"2024-10-22T11:24:54.138344Z","shell.execute_reply":"2024-10-22T11:24:54.137469Z","shell.execute_reply.started":"2024-10-22T11:24:54.131487Z"},"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-22T11:24:54.139875Z","iopub.status.busy":"2024-10-22T11:24:54.139575Z"},"trusted":true},"outputs":[],"source":["epochs = 101\n","total = start_epoch + epochs\n","\n","print(\"training started\")\n","\n","best_val_loss = float('inf')\n","patience = 15\n","no_improve = 0\n","\n","for epoch in range(start_epoch, total):\n","    model.train()\n","    train_loss = 0\n","    val_loss = 0\n","    \n","    for input_vector, label , planet in train_dataloader:\n","        optimizer.zero_grad()\n","        input_vector = input_vector.float().to(device)\n","        label = label.float().to(device)\n","        \n","        out = model(input_vector)\n","        loss = criterion(out, label)\n","        \n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","    \n","    train_loss /= len(train_dataloader)\n","    \n","    if epoch%5==0 and epoch>0:\n","        print(f\" label {(label[0][:3].cpu().detach().numpy())} , output {(out[0][:3].cpu().detach().numpy())}\")\n","\n","    if epoch==13:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 1e-8\n","            print(f\"Learning rate manually set to 1e-4 at epoch {epoch}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for input_vector, label , planet in val_dataloader:\n","            input_vector = input_vector.float().to(device)\n","            label = label.float().to(device)\n","            \n","            out = model(input_vector)\n","            loss = criterion(out, label)\n","            val_loss += loss.item()\n","    \n","    val_loss /= len(val_dataloader)\n","    \n","    prev = optimizer.param_groups[0]['lr']\n","    scheduler.step(val_loss)\n","    nex =optimizer.param_groups[0]['lr']\n","    \n","    if prev!=nex:\n","        print(\"LR decreased to \" , nex)\n","    \n","    print(f\"Epoch {epoch+1}/{total}, Train loss: {train_loss}, Val loss: {val_loss}\")\n","    \n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        no_improve = 0\n","        \n","        model_filename = f\"epoch{epoch}-loss{train_loss:.8f}.pth\"\n","        model_path = os.path.join(\"/kaggle/working\", model_filename)\n","        \n","        checkpoint = {\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'scheduler_state_dict': scheduler.state_dict(),\n","            'loss': train_loss,\n","        }\n","        torch.save(checkpoint, model_path)\n","        print(f\"Model saved at epoch {epoch}\")\n","        \n","    else:\n","        no_improve += 1\n","        if no_improve == patience:\n","            print(\"Early stopping triggered at epoch\", epoch)\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(f\"Current learning rate: {optimizer.param_groups[0]['lr']}\")\n","print(\"done\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# planet=1129361124\n","# airs_file=f\"/kaggle/input/arieldata/airs2k/{planet}_airs.npy\"\n","# # fgs_file=f\"/kaggle/input/dataset-ariel/fgs/{planet}_fgs.npy\"\n","\n","\n","# airs_arr = np.load(airs_file)\n","# # fgs_arr  = np.load(fgs_file) \n","\n","# airs_arr=(airs_arr-np.min(airs_arr))/(np.max(airs_arr)-np.min(airs_arr))\n","# # fgs_arr=(fgs_arr-np.min(fgs_arr))/(np.max(fgs_arr)-np.min(fgs_arr))\n","# initial_breakpoint=900\n","# buffer_size=80 \n","# smooth_window=200\n","# window_size=300\n","# airsbp = optimize_breakpoint(airs_arr,initial_breakpoint,window_size=window_size,buffer_size=buffer_size,smooth_window=smooth_window)\n","# # fgsbp = optimize_breakpoint(fgs_arr,initial_breakpoint,window_size=window_size,buffer_size=buffer_size,smooth_window=smooth_window)\n","# midpoint1 = len(airs_arr) // 2\n","# bp1 = [airsbp, 2 * midpoint1 - airsbp]\n","# airs_start   =  bp1[0] - buffer_size\n","# airs_end     =  bp1[0] + buffer_size\n","# airs_start1  =  bp1[1] - buffer_size\n","# airs_end1    =  bp1[1] + buffer_size\n","# # midpoint2 = len(fgs_arr) // 2\n","# # bp2 = [fgsbp, 2 * midpoint2 - fgsbp]\n","# # fgs_start  =    bp2[0] - buffer_size\n","# # fgs_end    =    bp2[0] + buffer_size\n","# # fgs_start1 =    bp2[1] - buffer_size\n","# # fgs_end1   =    bp2[1] + buffer_size\n","# airs_vector=  vector( airs_arr,  airs_start ,  airs_end , airs_start1 , airs_end1 )\n","# # fgs_vector =  vector( fgs_arr, fgs_start  ,   fgs_end , fgs_start1  , fgs_end1 )        \n","\n","\n","# # input_vector=  np.concatenate((airs_vector , fgs_vector))\n","# # input_vector=airs_vector\n","\n","# labels        = pd.read_csv(\"/kaggle/input/ariel-data-challenge-2024/train_labels.csv\")\n","# filtered_data = labels[labels[\"planet_id\"] == planet].iloc[0, 1:].values\n","# in_vector = torch.tensor(np.array(airs_vector))\n","# in_vector=in_vector.unsqueeze(0).float()\n","# output       = torch.tensor(filtered_data )\n","# print(in_vector.shape , output.shape)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# print(output[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model = WavelengthPredictor()\n","# model = nn.DataParallel(model)\n","# model = model.to(device)\n","\n","# weights=\"/kaggle/input/arieldata/ariel3_335.pth\"\n","\n","# checkpoint = torch.load(weights, map_location=device)\n","# model.load_state_dict(checkpoint['model_state_dict'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# model.eval()\n","# with torch.no_grad():\n","#     pred = model(in_vector)\n","\n","# # Print the output shape\n","# print(pred.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# print(pred[0][:5])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9188054,"sourceId":70367,"sourceType":"competition"},{"datasetId":5618537,"isSourceIdPinned":true,"sourceId":9498960,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
