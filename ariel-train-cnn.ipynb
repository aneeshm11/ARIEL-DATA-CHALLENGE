{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":70367,"databundleVersionId":9188054,"sourceType":"competition"},{"sourceId":9658530,"sourceType":"datasetVersion","datasetId":5618537,"isSourceIdPinned":true},{"sourceId":9695019,"sourceType":"datasetVersion","datasetId":5912377}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport pandas as pd\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-23T06:08:13.399181Z","iopub.execute_input":"2024-10-23T06:08:13.399765Z","iopub.status.idle":"2024-10-23T06:08:17.399280Z","shell.execute_reply.started":"2024-10-23T06:08:13.399705Z","shell.execute_reply":"2024-10-23T06:08:17.398465Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CNN2D_AIRS(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(CNN2D_AIRS, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.gn1 = nn.GroupNorm(4, out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.gn2 = nn.GroupNorm(4, out_channels)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        # x = self.pool(F.relu(self.gn1(self.conv1(x))))\n        # x = self.pool(F.relu(self.gn2(self.conv2(x))))\n\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n\n        return x\n\nclass CNN2D_FGS(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(CNN2D_FGS, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.gn1 = nn.GroupNorm(4, out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.gn2 = nn.GroupNorm(4, out_channels)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        # x = self.pool(F.relu(self.gn1(self.conv1(x))))\n        # x = self.pool(F.relu(self.gn2(self.conv2(x))))\n\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n\n        return x\n\nclass Model(nn.Module):\n    def __init__(self, airs_frames, fgs_frames):\n        super(Model, self).__init__()\n        self.cnn_airs = CNN2D_AIRS(1, 16)\n        self.cnn_fgs = CNN2D_FGS(1, 16)\n        \n        self.lstm_airs = nn.LSTM(16 * 8 * 89, 128, batch_first=True)\n        self.lstm_fgs = nn.LSTM(16 * 8 * 8, 128, batch_first=True)\n        \n        self.ln_airs = nn.LayerNorm(128)\n        self.ln_fgs = nn.LayerNorm(128)\n        \n        self.fc_light_curve_airs = nn.Sequential(\n            nn.Linear(airs_frames, 64),\n            nn.ReLU(),\n#             nn.LayerNorm(64),\n        )\n        \n        self.fc_light_curve_fgs = nn.Sequential(\n            nn.Linear(fgs_frames, 64),\n            nn.ReLU(),\n#             nn.LayerNorm(64),\n        )\n        \n        self.fc_combined = nn.Sequential(            \n            nn.Linear(128 + 128 + 64 + 64, 256),\n            nn.ReLU(),\n            nn.LayerNorm(256),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.LayerNorm(256),\n            nn.Linear(256, 283)\n        )\n    def forward(self, airs_ch0, fgs1, light_curve_airs, light_curve_fgs):\n        batch_size, frames, _, _, _ = airs_ch0.shape\n        \n        airs_features = self.cnn_airs(airs_ch0.view(-1, 1, 32, 356))\n        airs_features = airs_features.view(batch_size, frames, -1)\n        _, (airs_hidden, _) = self.lstm_airs(airs_features)\n        # airs_hidden = self.ln_airs(airs_hidden.squeeze(0))\n        airs_hidden = airs_hidden.squeeze(0)\n\n        \n        fgs_features = self.cnn_fgs(fgs1.view(-1, 1, 32, 32))\n        fgs_features = fgs_features.view(batch_size, frames, -1)\n        _, (fgs_hidden, _) = self.lstm_fgs(fgs_features)\n        # fgs_hidden = self.ln_fgs(fgs_hidden.squeeze(0))\n        fgs_hidden = fgs_hidden.squeeze(0)\n\n        \n        light_curve_airs_features = self.fc_light_curve_airs(light_curve_airs)\n        light_curve_fgs_features = self.fc_light_curve_fgs(light_curve_fgs)\n        \n        combined_features = torch.cat((airs_hidden, fgs_hidden, light_curve_airs_features, light_curve_fgs_features), dim=1)\n        \n        output = self.fc_combined(combined_features)\n        return output\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nairs_frames = 1125\nfgs_frames = 1125\nmodel = Model(airs_frames, fgs_frames).to(device) # small batch size model","metadata":{"execution":{"iopub.status.busy":"2024-10-23T06:08:17.401327Z","iopub.execute_input":"2024-10-23T06:08:17.401955Z","iopub.status.idle":"2024-10-23T06:08:17.409542Z","shell.execute_reply.started":"2024-10-23T06:08:17.401911Z","shell.execute_reply":"2024-10-23T06:08:17.408656Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class CNN2D_AIRS(nn.Module):\n#     def __init__(self, in_channels, out_channels):\n#         super(CNN2D_AIRS, self).__init__()\n#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n#         self.bn1 = nn.BatchNorm2d(out_channels)\n#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n#         self.bn2 = nn.BatchNorm2d(out_channels)\n#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n#     def forward(self, x):\n# #         x = self.pool(F.relu(self.bn1(self.conv1(x))))\n# #         x = self.pool(F.relu(self.bn2(self.conv2(x))))\n\n#         x = self.pool(F.relu(self.conv1(x)))\n#         x = self.pool(F.relu(self.conv2(x)))\n\n#         return x\n\n# class CNN2D_FGS(nn.Module):\n#     def __init__(self, in_channels, out_channels):\n#         super(CNN2D_FGS, self).__init__()\n#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n#         self.bn1 = nn.BatchNorm2d(out_channels)\n#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n#         self.bn2 = nn.BatchNorm2d(out_channels)\n#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n#     def forward(self, x):\n# #         x = self.pool(F.relu(self.bn1(self.conv1(x))))\n# #         x = self.pool(F.relu(self.bn2(self.conv2(x))))\n\n#         x = self.pool(F.relu(self.conv1(x)))\n#         x = self.pool(F.relu(self.conv2(x)))\n#         return x\n\n# class Model(nn.Module):\n#     def __init__(self, airs_frames, fgs_frames):\n#         super(Model, self).__init__()\n#         self.cnn_airs = CNN2D_AIRS(1, 16)\n#         self.cnn_fgs = CNN2D_FGS(1, 16)\n        \n#         self.lstm_airs = nn.LSTM(16 * 8 * 89, 128, batch_first=True)\n#         self.lstm_fgs = nn.LSTM(16 * 8 * 8, 128, batch_first=True)\n        \n#         self.bn_airs = nn.BatchNorm1d(128)\n#         self.bn_fgs = nn.BatchNorm1d(128)\n        \n#         self.fc_light_curve_airs = nn.Sequential(\n#             nn.Linear(airs_frames, 64),\n#             nn.ReLU()\n# #             nn.BatchNorm1d(64),\n\n#         )\n        \n#         self.fc_light_curve_fgs = nn.Sequential(\n#             nn.Linear(fgs_frames, 64),\n#             nn.ReLU()\n# #             nn.BatchNorm1d(64),\n\n#         )\n        \n#         self.fc_combined = nn.Sequential(            \n#             nn.Linear(128 + 128 + 64 + 64, 256),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(256),\n# #             nn.Dropout(0.15),\n#             nn.Linear(256, 256),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(256),\n# #             nn.Dropout(0.15),\n#             nn.Linear(256, 283)\n#         )\n\n#     def forward(self, airs_ch0, fgs1, light_curve_airs, light_curve_fgs):\n#         batch_size, frames, _, _, _ = airs_ch0.shape\n        \n#         airs_features = self.cnn_airs(airs_ch0.view(-1, 1, 32, 356))\n#         airs_features = airs_features.view(batch_size, frames, -1)\n#         _, (airs_hidden, _) = self.lstm_airs(airs_features)\n# #         airs_hidden = self.bn_airs(airs_hidden.squeeze(0))\n#         airs_hidden = airs_hidden.squeeze(0)\n        \n        \n#         fgs_features = self.cnn_fgs(fgs1.view(-1, 1, 32, 32))\n#         fgs_features = fgs_features.view(batch_size, frames, -1)\n#         _, (fgs_hidden, _) = self.lstm_fgs(fgs_features)\n# #         fgs_hidden = self.bn_fgs(fgs_hidden.squeeze(0))\n#         fgs_hidden = fgs_hidden.squeeze(0)\n        \n#         light_curve_airs_features = self.fc_light_curve_airs(light_curve_airs)\n#         light_curve_fgs_features = self.fc_light_curve_fgs(light_curve_fgs)\n        \n#         combined_features = torch.cat((airs_hidden, fgs_hidden, light_curve_airs_features, light_curve_fgs_features), dim=1)\n        \n#         output = self.fc_combined(combined_features)\n#         return output\n\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# airs_frames = 1125\n# fgs_frames = 1125\n# model = Model(airs_frames, fgs_frames).to(device) # for larger batch size ","metadata":{"execution":{"iopub.status.busy":"2024-10-23T06:08:17.411121Z","iopub.execute_input":"2024-10-23T06:08:17.411492Z","iopub.status.idle":"2024-10-23T06:08:17.821061Z","shell.execute_reply.started":"2024-10-23T06:08:17.411458Z","shell.execute_reply":"2024-10-23T06:08:17.819877Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"c=0\nfor x in model.parameters():\n    c+=x.numel()\nprint(c)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T06:08:17.823593Z","iopub.execute_input":"2024-10-23T06:08:17.823899Z","iopub.status.idle":"2024-10-23T06:08:17.829230Z","shell.execute_reply.started":"2024-10-23T06:08:17.823866Z","shell.execute_reply":"2024-10-23T06:08:17.828386Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def planetnumber(filename):\n    return int(filename.split('_')[0])\n\nclass ARIEL(Dataset):\n    def __init__(self, airs_dir1, airs_dir2, airs_dir3, airs_dir4, fgs_dir , start , end):\n        self.airs_dir1 = airs_dir1\n        self.airs_dir2 = airs_dir2\n        self.airs_dir3 = airs_dir3\n        self.airs_dir4 = airs_dir4\n        self.airs_full = os.listdir(self.airs_dir1) + os.listdir(self.airs_dir2) + os.listdir(self.airs_dir3) + os.listdir(self.airs_dir4) \n        \n        self.fgs_dir = fgs_dir\n        \n        self.airs_list = sorted(self.airs_full, key=planetnumber)[start:end]\n        self.fgs_list = sorted(os.listdir(self.fgs_dir), key=planetnumber)[start:end]\n        \n        self.labels = pd.read_csv(\"/kaggle/input/ariel-data-challenge-2024/train_labels.csv\")\n    \n    def __getitem__(self, index):\n        \n        planet= self.airs_list[index]\n        \n        if planet in os.listdir(self.airs_dir1):\n            airs_file = os.path.join(self.airs_dir1, planet )\n        \n        elif planet in os.listdir(self.airs_dir2):\n            airs_file = os.path.join(self.airs_dir2, planet )\n            \n        elif planet in os.listdir(self.airs_dir3):\n            airs_file = os.path.join(self.airs_dir3, planet )\n            \n        elif planet in os.listdir(self.airs_dir4):\n            airs_file = os.path.join(self.airs_dir4, planet )\n\n        \n                    \n        planet_num = planetnumber(planet)\n        fgs_file = f\"{self.fgs_dir}/{planet_num}_fgs.npy\" \n        \n        airs_arr_frames = np.load(airs_file)\n        fgs_arr_frames = np.load(fgs_file)\n        \n        airs_arr_frames = airs_arr_frames.reshape(1125, 32, 356)\n        fgs_arr_frames = fgs_arr_frames.reshape(1125, 32, 32)\n        \n        airs_1d = np.sum(airs_arr_frames, axis=(1, 2))\n        fgs_1d = np.sum(fgs_arr_frames, axis=(1, 2))\n        \n        airs_1d = (airs_1d-np.min(airs_1d))/(np.max(airs_1d)-np.min(airs_1d))\n        fgs_1d  = (fgs_1d-np.min(fgs_1d))/(np.max(fgs_1d)-np.min(fgs_1d))\n\n        \n        airs_arr_frames = torch.from_numpy(airs_arr_frames).float().unsqueeze(1)  # Add channel dimension\n        fgs_arr_frames = torch.from_numpy(fgs_arr_frames).float().unsqueeze(1)  # Add channel dimension\n        \n        airs_1d = torch.from_numpy(airs_1d).float()\n        fgs_1d = torch.from_numpy(fgs_1d).float()\n        \n        filtered_data = self.labels[self.labels[\"planet_id\"] == planet_num].iloc[0, 1:].values\n        output = torch.tensor(filtered_data).float()\n        \n        # return  [planet , airs_file , fgs_file]\n        return {\n            'airs_frames': airs_arr_frames,\n            'fgs_frames': fgs_arr_frames,\n            'airs_1d': airs_1d,\n            'fgs_1d': fgs_1d,\n            'label': output\n        }\n     \n    def __len__(self):\n        return len(self.airs_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T06:08:17.830592Z","iopub.execute_input":"2024-10-23T06:08:17.830885Z","iopub.status.idle":"2024-10-23T06:08:17.849703Z","shell.execute_reply.started":"2024-10-23T06:08:17.830854Z","shell.execute_reply":"2024-10-23T06:08:17.848914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\nairs_frames = 1125\nfgs_frames = 1125\n\nmodel = Model(airs_frames, fgs_frames).to(device)\nmodel = nn.DataParallel(model)\nmodel = model.to(device)\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-2 , weight_decay=1e-4) \nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.50, patience=3 , min_lr=1e-8)\n\n\n\nweights = None  \n# weights=\"/kaggle/input/arieldata/epoch450.pth\"\n\n\nif weights:\n    checkpoint = torch.load(weights, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n    start_epoch = checkpoint['epoch'] + 1\n    print(f\"Resuming from epoch {start_epoch}\")\n    print(f\"Resuming learning rate: {optimizer.param_groups[0]['lr']}\")\nelse:\n    start_epoch = 0\n\ntrain_batchsize = 5\nval_batchsize   = 2\n\npart1=\"/kaggle/input/arieldata/airs-p1\"\npart2=\"/kaggle/input/arieldata/airs-p2\"\npart3=\"/kaggle/input/arieldata/airs-p3\"\npart4=\"/kaggle/input/arieldata/airs-p4\"\n\npart5=\"/kaggle/input/arieldata/fgs-p\"\n\ntrain_data = ARIEL(part1 , part2, part3, part4, part5, start=0 , end=635)\nval_data   = ARIEL(part1 , part2, part3, part4, part5, start=635 , end=665)\n\ntrain_dataloader = DataLoader(train_data, batch_size=train_batchsize, shuffle=True, num_workers=8)\nval_dataloader   = DataLoader(val_data,   batch_size=val_batchsize, shuffle=False, num_workers=8)\n\nprint(f\"Training batches: {len(train_dataloader)}, Validation batches: {len(val_dataloader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T06:08:17.850858Z","iopub.execute_input":"2024-10-23T06:08:17.851140Z","iopub.status.idle":"2024-10-23T06:08:19.214054Z","shell.execute_reply.started":"2024-10-23T06:08:17.851109Z","shell.execute_reply":"2024-10-23T06:08:19.213204Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob\n\nepochs = 141\ntotal = start_epoch + epochs\nprint(\"training started\")\nbest_val_loss = float('inf')\npatience = 15\nno_improve = 0\ncount = 0\n\ndef cleanup_old_checkpoints(directory):\n    \"\"\"Remove all .pth files in the specified directory\"\"\"\n    checkpoint_files = glob.glob(os.path.join(directory, \"*.pth\"))\n    for f in checkpoint_files:\n        try:\n            os.remove(f)\n            print(f\"Removed old checkpoint: {f}\")\n        except Exception as e:\n            print(f\"Error removing {f}: {e}\")\n\nfor epoch in range(start_epoch, total):\n    model.train()\n    train_loss = 0\n    val_loss = 0\n    \n    for batch in train_dataloader:\n        optimizer.zero_grad()\n        airs_frames = batch['airs_frames'].to(device)\n        fgs_frames = batch['fgs_frames'].to(device)\n        airs_1d = batch['airs_1d'].to(device)\n        fgs_1d = batch['fgs_1d'].to(device)\n        label = batch['label'].to(device)\n        out = model(airs_frames, fgs_frames, airs_1d, fgs_1d)\n        \n        loss = criterion(out, label)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n    \n    train_loss /= len(train_dataloader)\n    \n    if epoch%5==0 and epoch>0:\n        print(f\" label {(label[0][:3].cpu().detach().numpy())} , output {(out[0][:3].cpu().detach().numpy())}\")\n        \n    if no_improve==7 and count==0 and optimizer.param_groups[0]['lr'] > 1e-6:\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = 5e-7\n            print(f\"Learning rate manually set to 5e-7 at epoch {epoch}\")\n        count+=1\n    \n    model.eval()\n    with torch.no_grad():\n        for batch in val_dataloader:\n            airs_frames = batch['airs_frames'].to(device)\n            fgs_frames = batch['fgs_frames'].to(device)\n            airs_1d = batch['airs_1d'].to(device)\n            fgs_1d = batch['fgs_1d'].to(device)\n            label = batch['label'].to(device)\n            out = model(airs_frames, fgs_frames, airs_1d, fgs_1d)\n            loss = criterion(out, label)\n            val_loss += loss.item()\n    \n    val_loss /= len(val_dataloader)\n    prev = optimizer.param_groups[0]['lr']\n    scheduler.step(val_loss)\n    nex = optimizer.param_groups[0]['lr']\n    \n    if prev!=nex:\n        print(\"LR decreased to \", nex)\n    \n    print(f\"Epoch {epoch+1}/{total}, Train loss: {train_loss}, Val loss: {val_loss}\")\n    \n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        no_improve = 0\n        \n        cleanup_old_checkpoints(\"/kaggle/working\")\n        \n        model_filename = f\"epoch{epoch}.pth\"\n        model_path = os.path.join(\"/kaggle/working\", model_filename)\n        \n        checkpoint = {\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'loss': train_loss,\n        }\n        torch.save(checkpoint, model_path)        \n        print(f\"Model saved at epoch {epoch}, old files clean, {len(os.listdir('/kaggle/working'))}\")\n        \n    else:\n        no_improve += 1\n        if no_improve == patience:\n            print(\"Early stopping triggered at epoch\", epoch)\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T06:08:19.215422Z","iopub.execute_input":"2024-10-23T06:08:19.215732Z","iopub.status.idle":"2024-10-23T06:08:38.222408Z","shell.execute_reply.started":"2024-10-23T06:08:19.215698Z","shell.execute_reply":"2024-10-23T06:08:38.220617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_filename = \"lastrun.pth\"\nmodel_path = os.path.join(\"/kaggle/working\", model_filename)\ncheckpoint = {\n    'epoch': epoch,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'scheduler_state_dict': scheduler.state_dict(),\n    'loss': train_loss,\n}\ntorch.save(checkpoint, model_path)        \nprint(f\"Model saved at epoch {epoch}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T06:08:38.223601Z","iopub.status.idle":"2024-10-23T06:08:38.223989Z","shell.execute_reply.started":"2024-10-23T06:08:38.223803Z","shell.execute_reply":"2024-10-23T06:08:38.223822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.eval()  \n# model_filename = f\"epoch{epoch}-loss{epoch_loss:.8f}.pth\"\n# model_path = os.path.join(\"/kaggle/working\", model_filename)\n\n# checkpoint = {\n#     'epoch': epoch,\n#     'model_state_dict': model.state_dict(),\n#     'optimizer_state_dict': optimizer.state_dict(),\n#     'scheduler_state_dict': scheduler.state_dict(),\n#     'loss': epoch_loss,\n# }\n# torch.save(checkpoint, model_path)        \n# print(f\"Model saved at epoch {epoch}\")\n# print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T06:08:38.225075Z","iopub.status.idle":"2024-10-23T06:08:38.225471Z","shell.execute_reply.started":"2024-10-23T06:08:38.225285Z","shell.execute_reply":"2024-10-23T06:08:38.225305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Learning rate final to {optimizer.param_groups[0]['lr']} \")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T06:08:38.226837Z","iopub.status.idle":"2024-10-23T06:08:38.227338Z","shell.execute_reply.started":"2024-10-23T06:08:38.227070Z","shell.execute_reply":"2024-10-23T06:08:38.227096Z"}},"outputs":[],"execution_count":null}]}