{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"competition","sourceId":70367,"databundleVersionId":9188054},{"sourceType":"datasetVersion","sourceId":9451212,"datasetId":5618537,"databundleVersionId":9657915}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os \nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy.stats import skew\nfrom scipy.stats import kurtosis\nfrom scipy.stats import entropy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-17T15:16:33.137796Z","iopub.execute_input":"2024-10-17T15:16:33.138685Z","iopub.status.idle":"2024-10-17T15:16:33.144720Z","shell.execute_reply.started":"2024-10-17T15:16:33.138635Z","shell.execute_reply":"2024-10-17T15:16:33.143269Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"x=\"/kaggle/input/arieldata/fgs2k/100468857_fgs.npy\"\narr=np.load(x)\nprint(arr.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:16:33.324087Z","iopub.execute_input":"2024-10-17T15:16:33.324935Z","iopub.status.idle":"2024-10-17T15:16:33.333945Z","shell.execute_reply.started":"2024-10-17T15:16:33.324886Z","shell.execute_reply":"2024-10-17T15:16:33.332865Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(2700,)\n","output_type":"stream"}]},{"cell_type":"code","source":"def process_signal(signal, gain, offset, dead, flat, dark, linear_corr):\n    # ADC conversion\n    signal = signal * gain + offset\n    \n    # Clean flat, dark, dead\n    flat = np.ma.masked_where(dead, flat)\n    dark = np.ma.masked_where(dead, dark)\n    flat = np.tile(flat, (signal.shape[0], 1, 1))\n    dark = np.tile(dark, (signal.shape[0], 1, 1))\n    dead = np.tile(dead, (signal.shape[0], 1, 1))\n    \n    signal = np.ma.masked_where(dead, signal)\n    signal = (signal - dark) / (flat - dark)\n    # Apply linear correction\n#     linear_corr = np.flip(linear_corr, axis=0)\n#     for x in range(signal.shape[1]):\n#         for y in range(signal.shape[2]):\n#             poli = np.poly1d(linear_corr[:, x, y])\n#             signal[:, x, y] = poli(signal[:, x, y])\n    # Get CDS\n    signal = signal[1::2, :, :] - signal[::2, :, :]\n    \n    return signal\n\ndef bin_obs(cds_signal, binning):\n    cds_transposed = cds_signal.transpose(1, 2, 0)\n    binned_shape = (cds_transposed.shape[0], cds_transposed.shape[1], cds_transposed.shape[2] // binning)\n    cds_binned = np.zeros(binned_shape)\n    for i in range(binned_shape[2]):\n        cds_binned[:, :, i] = np.sum(cds_transposed[:, :, i*binning:(i+1)*binning], axis=2)\n    return cds_binned.transpose(2, 0, 1)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:20:13.224845Z","iopub.execute_input":"2024-10-17T15:20:13.225291Z","iopub.status.idle":"2024-10-17T15:20:13.235846Z","shell.execute_reply.started":"2024-10-17T15:20:13.225253Z","shell.execute_reply":"2024-10-17T15:20:13.234503Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def vector(data, start, end , start1 , end1):\n    \n    region1= data[:start]  \n    \n    region2=data[start:end]\n    region3=data[end:start1]\n    region4=data[start1:end1]\n\n    region5=data[end1:]\n\n    uncovered = (  np.mean(region1) + np.mean(region5)  )/2\n    \n    reduction1= ( uncovered - np.mean(region2)    ) / uncovered\n    reduction2= ( uncovered - np.mean(region3)   )  / uncovered\n    reduction3= ( uncovered - np.mean(region4)   )  / uncovered\n        \n    \n    slope=(data[end]-data[start])/(end-start)\n    slope1=(data[end1]-data[start1])/(end1-start1)\n    \n    nr = np.mean(data)    / np.std(data)\n    nr1= np.mean(region1) / np.std(region1)\n    nr2= np.mean(region2) / np.std(region2)\n    nr3= np.mean(region3) / np.std(region3)\n    nr4= np.mean(region4) / np.std(region4)\n    nr5= np.mean(region5) / np.std(region5)\n   \n    skewness= skew(data)\n\n#     input_vector = np.array([ slope, slope1 , reduction1, reduction2, reduction3 ] )\n    input_vector = np.array([ slope, slope1 , reduction1, reduction2, reduction3 ,nr,nr1,nr2,nr3,nr4,nr5 ,skewness] )\n\n    return input_vector\n","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:16:33.590991Z","iopub.execute_input":"2024-10-17T15:16:33.591403Z","iopub.status.idle":"2024-10-17T15:16:33.601321Z","shell.execute_reply.started":"2024-10-17T15:16:33.591364Z","shell.execute_reply":"2024-10-17T15:16:33.599988Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from scipy.signal import savgol_filter\n\ndef smooth_data(data, window_size):\n    return savgol_filter(data, window_size, 3)\n\ndef optimize_breakpoint(data, initial_breakpoint, window_size, buffer_size, smooth_window):\n    best_breakpoint = initial_breakpoint\n    best_score = float(\"-inf\")\n    midpoint = len(data) // 2\n    smoothed_data = smooth_data(data, smooth_window)\n#     smoothed_data=data\n    for i in range(-window_size, window_size):\n        new_breakpoint = initial_breakpoint + i\n        if new_breakpoint > buffer_size and new_breakpoint < midpoint - buffer_size:\n            region1 = data[: new_breakpoint - buffer_size]\n            region2 = data[\n                new_breakpoint\n                + buffer_size : 2 * midpoint\n                - new_breakpoint\n                - buffer_size\n            ]\n            region3 = data[2 * midpoint - new_breakpoint + buffer_size :]\n\n            breakpoint_region1 = smoothed_data[new_breakpoint - buffer_size: new_breakpoint + buffer_size]\n            breakpoint_region2 = smoothed_data[new_breakpoint - buffer_size: new_breakpoint + buffer_size]\n\n            mean_diff = abs(np.mean(region1) - np.mean(region2)) + abs(\n                np.mean(region2) - np.mean(region3)\n            )\n            var_sum = np.var(region1) + np.var(region2) + np.var(region3)\n            range_at_breakpoint1 = (np.max(breakpoint_region1) - np.min(breakpoint_region1))\n            range_at_breakpoint2 = (np.max(breakpoint_region2) - np.min(breakpoint_region2))\n\n            mean_range_at_breakpoint = (range_at_breakpoint1 + range_at_breakpoint2) / 2\n\n            score = mean_diff - 0.5 * var_sum + mean_range_at_breakpoint\n\n            if score > best_score:\n                best_score = score\n                best_breakpoint = new_breakpoint\n\n                \n    return best_breakpoint","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:16:33.752425Z","iopub.execute_input":"2024-10-17T15:16:33.752838Z","iopub.status.idle":"2024-10-17T15:16:33.823124Z","shell.execute_reply.started":"2024-10-17T15:16:33.752800Z","shell.execute_reply":"2024-10-17T15:16:33.822038Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"initial_breakpoint=900\nbuffer_size=80 \nsmooth_window=200\nwindow_size=300","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:16:34.263945Z","iopub.execute_input":"2024-10-17T15:16:34.264707Z","iopub.status.idle":"2024-10-17T15:16:34.269904Z","shell.execute_reply.started":"2024-10-17T15:16:34.264658Z","shell.execute_reply":"2024-10-17T15:16:34.268779Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class WavelengthPredictor(nn.Module):\n    def __init__(self):\n        super(WavelengthPredictor, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(12, 32),\n            nn.ReLU(),\n            nn.BatchNorm1d(32),\n            \n            nn.Linear(32, 64),\n            nn.ReLU(),\n            nn.BatchNorm1d(64),\n            \n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.BatchNorm1d(128),\n            \n            nn.Linear(128, 256),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            \n            nn.Linear(256, 283)\n        )\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:16:34.893884Z","iopub.execute_input":"2024-10-17T15:16:34.894323Z","iopub.status.idle":"2024-10-17T15:16:34.902829Z","shell.execute_reply.started":"2024-10-17T15:16:34.894283Z","shell.execute_reply":"2024-10-17T15:16:34.901448Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# class WavelengthPredictor(nn.Module):\n#     def __init__(self):\n#         super(WavelengthPredictor, self).__init__()\n#         self.model = nn.Sequential(\n#             nn.Linear(24, 48),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(48),\n            \n#             nn.Linear(48, 96),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(96),\n            \n#             nn.Linear(96, 192),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(192),\n            \n#             nn.Linear(192, 256),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(256),\n            \n#             nn.Linear(256, 283)\n#         )\n    \n#     def forward(self, x):\n#         return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:16:36.621219Z","iopub.execute_input":"2024-10-17T15:16:36.621744Z","iopub.status.idle":"2024-10-17T15:16:36.629392Z","shell.execute_reply.started":"2024-10-17T15:16:36.621694Z","shell.execute_reply":"2024-10-17T15:16:36.628079Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = WavelengthPredictor()\nmodel = nn.DataParallel(model)\nmodel = model.to(device)\n\nweights=\"/kaggle/input/arieldata/epoch180.pth\"\n# weights=\"/kaggle/input/arieldata/ariel3_335.pth\"\ncheckpoint = torch.load(weights, map_location=device)\nmodel.load_state_dict(checkpoint['model_state_dict'])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-21T18:39:56.319042Z","iopub.execute_input":"2024-09-21T18:39:56.319480Z","iopub.status.idle":"2024-09-21T18:39:56.575530Z","shell.execute_reply.started":"2024-09-21T18:39:56.319443Z","shell.execute_reply":"2024-09-21T18:39:56.574173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.set_printoptions(precision=10)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:16:38.842828Z","iopub.execute_input":"2024-10-17T15:16:38.843622Z","iopub.status.idle":"2024-10-17T15:16:38.848002Z","shell.execute_reply.started":"2024-10-17T15:16:38.843575Z","shell.execute_reply":"2024-10-17T15:16:38.846912Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"results=[]","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:16:39.088665Z","iopub.execute_input":"2024-10-17T15:16:39.089115Z","iopub.status.idle":"2024-10-17T15:16:39.094030Z","shell.execute_reply.started":"2024-10-17T15:16:39.089072Z","shell.execute_reply":"2024-10-17T15:16:39.092812Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import re\ndef extract_number(filename):\n    number = re.search(r'\\d+', filename).group()  \n    return int(number)\n\nmode=\"train\"\nnum=15\n\nstart= 0\nend  = 600\nadc_info = pd.read_csv(f'/kaggle/input/ariel-data-challenge-2024/{mode}_adc_info.csv')                                                       \n                                                       \nplanets = sorted(os.listdir(f\"/kaggle/input/ariel-data-challenge-2024/{mode}\"), key=extract_number)[start:end]\n\n# planets= sorted(os.listdir(\"/kaggle/input/arieldata/airs-p3\") , key=extract_number)[:num]\n# planets = [extract_number(planet) for planet in planets]\n\n\nprint(planets[0])\nprint(len(planets))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:17:07.392263Z","iopub.execute_input":"2024-10-17T15:17:07.392692Z","iopub.status.idle":"2024-10-17T15:17:07.409210Z","shell.execute_reply.started":"2024-10-17T15:17:07.392655Z","shell.execute_reply":"2024-10-17T15:17:07.408064Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"785834\n600\n","output_type":"stream"}]},{"cell_type":"code","source":"total_up   = []\ntotal_down = []\n\nfor planet in planets:\n    planet = int(planet) \n\n    selected_adc_info = adc_info.loc[adc_info['planet_id'] == planet]\n    \n    print(f\"\\nProcessing planet: {planet}\")\n\n    airs_dark        = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/AIRS-CH0_calibration/dark.parquet').values.reshape(32, 356)\n    airs_dead        = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/AIRS-CH0_calibration/dead.parquet').values.reshape(32, 356)\n    airs_flat        = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/AIRS-CH0_calibration/flat.parquet').values.reshape(32, 356)\n    airs_linear_corr = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/AIRS-CH0_calibration/linear_corr.parquet').values.reshape(6, 32, 356)\n    airs_ch0         = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/AIRS-CH0_signal.parquet').values\n    airs_ch0_gain   = selected_adc_info['AIRS-CH0_adc_gain'].values[0]\n    airs_ch0_offset = selected_adc_info['AIRS-CH0_adc_offset'].values[0]\n    airs_ch0 = airs_ch0.reshape(11250, 32, 356)\n        \n    \n    fgs_dark         = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/FGS1_calibration/dark.parquet').values.reshape(32, 32)\n    fgs_dead         = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/FGS1_calibration/dead.parquet').values.reshape(32, 32)\n    fgs_flat         = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/FGS1_calibration/flat.parquet').values.reshape(32, 32)\n    fgs_linear_corr  = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/FGS1_calibration/linear_corr.parquet').values.reshape(6, 32, 32)\n    fgs1             = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{mode}/{planet}/FGS1_signal.parquet').values\n    fgs1_gain       = selected_adc_info['FGS1_adc_gain'].values[0]\n    fgs1_offset     = selected_adc_info['FGS1_adc_offset'].values[0]\n    fgs1 = fgs1.reshape(135000, 32, 32) \n    \n    airs_ch0_processed = process_signal(airs_ch0, airs_ch0_gain, airs_ch0_offset, airs_dead, airs_flat, airs_dark, airs_linear_corr)\n    fgs1_processed = process_signal(fgs1, fgs1_gain, fgs1_offset, fgs_dead, fgs_flat, fgs_dark, fgs_linear_corr)\n    \n    \n    airs_frames = bin_obs(airs_ch0_processed, binning=2)\n    fgs_frames  = bin_obs(fgs1_processed, binning=(25))\n    print(airs_frames.shape , fgs_frames.shape)\n    \n    break\n    \n    binned_fgs_array=np.sum(airs_frames , axis=(1,2))\n    binned_airs_array=np.sum(fgs1_frames , axis=(1,2))\n\n    \n    airs_arr = binned_airs_array\n    airs_arr=(airs_arr-np.min(airs_arr))/(np.max(airs_arr)-np.min(airs_arr))\n    \n    fgs_arr  = binned_fgs_array\n    fgs_arr=(fgs_arr-np.min(fgs_arr))/(np.max(fgs_arr)-np.min(fgs_arr))\n    \n    print(airs_arr.shape ,fgs_arr.shape )\n\n    airsbp = optimize_breakpoint(airs_arr,initial_breakpoint,window_size=window_size,buffer_size=buffer_size,smooth_window=smooth_window)    \n    fgsbp = optimize_breakpoint(fgs_arr,initial_breakpoint,window_size=window_size,buffer_size=buffer_size,smooth_window=smooth_window)\n\n    midpoint1 = len(airs_arr) // 2\n    bp1 = [airsbp, 2 * midpoint1 - airsbp]\n    airs_start   =  bp1[0] - buffer_size\n    airs_end     =  bp1[0] + buffer_size\n    airs_start1  =  bp1[1] - buffer_size\n    airs_end1    =  bp1[1] + buffer_size\n    \n    midpoint2 = len(fgs_arr) // 2\n    bp2 = [fgsbp, 2 * midpoint2 - fgsbp]\n    fgs_start  =    bp2[0] - buffer_size\n    fgs_end    =    bp2[0] + buffer_size\n    fgs_start1 =    bp2[1] - buffer_size\n    fgs_end1   =    bp2[1] + buffer_size\n\n\n    airs_vector=  vector( airs_arr,  airs_start ,  airs_end , airs_start1 , airs_end1 )\n    fgs_vector =  vector( fgs_arr, fgs_start  ,   fgs_end , fgs_start1  , fgs_end1 )        \n    \n    \n    input_vector=  np.concatenate((airs_vector , fgs_vector))\n#     input_vector=  (airs_vector + fgs_vector )/2\n#     input_vector = torch.tensor(np.array(input_vector))\n\n    \n#     labels        = pd.read_csv(\"/kaggle/input/ariel-data-challenge-2024/test_labels.csv\")\n#     filtered_data = labels[labels[\"planet_id\"] == planet].iloc[0, 1:].values\n    \n#     print(filtered_data[:10])\n#     print(filtered_data.shape)\n    \n    input_vector  =  torch.tensor(np.array(airs_vector)).unsqueeze(0).float().to(device)\n    print(input_vector.shape)\n    \n    model.eval()\n    with torch.no_grad():\n        out=model(input_vector)\n        \n    if mode==\"train\":\n\n        labels  = pd.read_csv(\"/kaggle/input/ariel-data-challenge-2024/train_labels.csv\")\n        true    = labels[labels[\"planet_id\"] == planet].iloc[0, 1:].values\n        true    = torch.tensor(true).unsqueeze(0).to(device)\n        l    = nn.MSELoss()\n        loss = l(out , torch.tensor(true))\n        print(f\"Loss :{loss.item():.7f} , Out:{out[0][:5]} , True:{true[0][:5]}\")\n        \n        up=[]\n        down=[]\n        for o ,t  in zip(out[0] , true[0]):\n            if o>t:\n                up.append(o/t)\n            elif t>o:\n                down.append(t/o)\n            \n        total_up.append(len(up))\n        total_down.append(len(down))\n\n#     if mode==\"test\":\n#         print(f\"Out:{out[0][:5]} \")\n        \n    count+=1\n    print(f\"{count} completed of {len(planets)} \")\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:21:21.412930Z","iopub.execute_input":"2024-10-17T15:21:21.413419Z","iopub.status.idle":"2024-10-17T15:21:40.119391Z","shell.execute_reply.started":"2024-10-17T15:21:21.413377Z","shell.execute_reply":"2024-10-17T15:21:40.118180Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"\nProcessing planet: 785834\n(2812, 32, 356) (2700, 32, 32)\n","output_type":"stream"}]}]}